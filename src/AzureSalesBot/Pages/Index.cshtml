@page
@using System
@using System.Net.Http.Headers
@using System.Text.RegularExpressions
@using Azure.Core
@using Azure.Identity

<!doctype html>
<meta charset="utf-8">
<title>Azure Sales Bot</title>

<style>
body{font-family:system-ui;margin:2rem;display:grid;gap:1rem}
button{padding:.6rem 1.2rem;font-size:1rem;border:2px solid #000;background:#fff}
#log{font-family:monospace;white-space:pre;max-height:10rem;overflow:auto;background:#f4f4f4;padding:.5rem}
</style>

<h1>Realtime Voice - Azure Sales Bot</h1>

@{
    this.Layout = null;

    // Define a regex that captures everything between "https://" and ".services.ai.azure.com"
    //var serviceName = "https://ai-account-gs5kjqfpmjm2y.services.ai.azure.com/api/projects/azuresalesbot-20250704";
    var serviceName = Environment.GetEnvironmentVariable("AZURE_AI_PROJECT_ENDPOINT");
    var pattern = @"https://(?<account>[^\.]+)\.services\.ai\.azure\.com";
    var match = Regex.Match(serviceName, pattern);

    // Authenticate with Azure using DefaultAzureCredential
    var credential = new DefaultAzureCredential(false);
    var accessToken = credential.GetToken(new TokenRequestContext(new[] { "https://cognitiveservices.azure.com/.default" }));

    // Save these variables for later use in the JavaScript code below
    var endpoint = $"wss://{match.Groups["account"].Value}.cognitiveservices.azure.com/voice-agent/realtime";
    var apiVersion = "2025-05-01-preview";
    var gptModel = "gpt-4o";
    var accessTokenString = accessToken.Token.ToString();
}

<br/>
<textarea id="instructions" rows="40" cols="40" placeholder="Enter instructions for the AI model...">
    Your name is Steven and you are a Microsoft Azure Specialist Salesperson. Your role is to engage in natural, extended conversations with customers about Microsoft Azure. You are confident, friendly, and casual—like a knowledgeable and approachable expert who is here to help.

    You have deep, up-to-date knowledge of all Azure services, including but not limited to:

    Compute (VMs, App Services, AKS)
    Storage (Blob, Files, Disks)
    Networking (VNet, ExpressRoute, Load Balancers)
    Identity (Azure AD, Entra)
    Security (Defender for Cloud, Sentinel)
    AI & ML (Azure OpenAI, Cognitive Services, ML Studio)
    DevOps (GitHub, Azure DevOps, Pipelines)
    Databases (SQL, Cosmos DB, PostgreSQL)
    Cost Management and Licensing
    Hybrid and Multicloud (Arc, Stack)
    Industry-specific solutions

    Your goal is to understand the customer's needs before offering solutions. Start by asking open-ended, thoughtful questions to uncover their goals, challenges, and current environment. Only after gaining a clear understanding should you begin recommending Azure services or architectures.

    You are proactive in guiding the conversation, but never pushy. You explain technical concepts clearly and adapt your depth based on the customer's knowledge level. You can handle both business and technical audiences.

    Always maintain a tone that is:

    Friendly and conversational
    Confident but not arrogant
    Curious and helpful
    Respectful and inclusive
    
    You may ask follow-up questions like:

    "What kind of workloads are you running today?"
    "Are you already using any cloud services?"
    "What are your top priorities—cost, performance, security, or something else?"
    "Do you have any compliance or data residency requirements?"

    If the customer asks about something outside Azure, you can briefly acknowledge it and steer the conversation back to Azure's capabilities or integrations.

    You are here to help the customer succeed with Azure—whether they're just getting started or scaling globally.
</textarea>

<div>
  <button id="start">Start</button>
  <button id="stop" disabled>Stop</button>
</div>

<pre id="log"></pre>

<script>

/* ---------- tweakables ---------- */
const SAMPLE_RATE_IN  = 48_000;   // what the browser gives us
const SAMPLE_RATE_OUT = 24_000;   // what the API expects (pcm16, mono)
const CHUNK = 2048;               // scriptProcessor buffer size

/* ---------- helpers ---------- */
const log = msg => (log.el.textContent += msg + '\n');
log.el = document.getElementById('log');

function downsample(float32 /*Float32Array*/) {

  if (SAMPLE_RATE_OUT === SAMPLE_RATE_IN) return float32;

  const ratio = SAMPLE_RATE_IN / SAMPLE_RATE_OUT;
  const out   = new Int16Array(Math.round(float32.length / ratio));

  let iOut = 0, iIn = 0;

  while (iOut < out.length) {
    const nextIn = Math.round((iOut + 1) * ratio);
    let sum = 0, count = 0;
    for (; iIn < nextIn && iIn < float32.length; iIn++) {
      sum += float32[iIn]; count++;
    }
    out[iOut++] = Math.max(-1, Math.min(1, sum / count)) * 0x7FFF;
  }

  return out;
}

const b64 = buf => btoa(String.fromCharCode(...new Uint8Array(buf)));

/* ---------- main ---------- */
let ws, audioCtx, micStream, procNode, playingQueue = [], playTime = 0;

async function start() {

  // 1. open websocket
  ws = new WebSocket(`@endpoint?api-version=@apiVersion&model=@gptModel&authorization=bearer+@accessTokenString`);

  ws.addEventListener('open', () => {

    ws.send(JSON.stringify({
      type: 'session.update',
      session: {
            instructions: document.getElementById("instructions").value.trim() || "No instructions provided.",
            input_audio_transcription: {
                model: 'azure-fast-transcription'
            },
            modalities: ['text', 'audio'],
            turn_detection: {
                type: 'server_vad',
                end_of_utterance_detection: null
            },
            input_audio_noise_reduction: null,
            input_audio_echo_cancellation: null,
            voice: {
                name: 'en-US-Andrew:DragonHDLatestNeural',
                type: 'azure-standard',
                temperature: 0.8,
                rate: '1'
            }
            // voice: {
            //     name: 'en-US-CustomNeural',
            //     type: 'azure-custom',
            //     endpoint_id: 'c6c33157-b00d-4260-ada0-e1a88e2684c2',
            //     temperature: 0.8
            // }
        }
    }));

    log('🔗 websocket open – session.update sent');
  });

  ws.addEventListener('message', onWsMessage);
  ws.addEventListener('close',  () => log('🔌 websocket closed'));
  ws.addEventListener('error',  e  => log('⚠️  ws error ' + e));

  // add auth headers (WebSocket API doesn't allow headers directly; use sub-protocol hack)
  ws.onopen = null; // we already set above; to keep code terser

  // 2. capture mic
  const stream = await navigator.mediaDevices.getUserMedia({audio: {sampleRate: SAMPLE_RATE_IN, channelCount: 1}});
  audioCtx   = new (window.AudioContext || window.webkitAudioContext)({sampleRate: SAMPLE_RATE_IN});
  micStream  = audioCtx.createMediaStreamSource(stream);
  procNode   = audioCtx.createScriptProcessor(CHUNK, 1, 1);

  procNode.onaudioprocess = e => {
    if (ws.readyState !== 1) return;
    const floatData = e.inputBuffer.getChannelData(0).slice(0); // clone
    const int16     = downsample(floatData);
    ws.send(JSON.stringify({
      type:  'input_audio_buffer.append',
      audio: b64(int16.buffer)
    }));
  };

  micStream.connect(procNode).connect(audioCtx.destination);
  log('🎙️  microphone streaming');

  document.getElementById('start').disabled = true;
  document.getElementById('stop').disabled  = false;
}

function stop() {
  ws?.close();
  procNode?.disconnect();
  micStream?.disconnect();
  audioCtx?.close();
  playingQueue = [];
  document.getElementById('start').disabled = false;
  document.getElementById('stop').disabled  = true;
}

function onWsMessage(ev) {

  const evt = JSON.parse(ev.data);

  switch (evt.type) {

    case 'response.audio.delta':
      playPcm(evt.delta);
      break;

    case 'response.audio_transcript.done':
      log('📝 ' + evt.transcript);
      break;

    default:
      if (!evt.type.startsWith('input_audio')) log('📨 ' + evt.type);
  }
}

/* ----- tiny PCM player for 24 kHz mono pcm16 ----- */
function playPcm(base64) {

  const bytes  = Uint8Array.from(atob(base64), c => c.charCodeAt(0));
  const int16  = new Int16Array(bytes.buffer);
  const float  = new Float32Array(int16.length);
  for (let i = 0; i < int16.length; i++) float[i] = int16[i] / 0x7FFF;

  const buf = audioCtx.createBuffer(1, float.length, SAMPLE_RATE_OUT);
  buf.getChannelData(0).set(float);

  const src = audioCtx.createBufferSource();
  src.buffer = buf;
  src.connect(audioCtx.destination);

  const now = audioCtx.currentTime;
  playTime = Math.max(playTime, now) + buf.duration;
  src.start(playTime - buf.duration);  // queue-up
}

document.getElementById('start').onclick = start;
document.getElementById('stop').onclick  = stop;

</script>